{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87ade1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# importing the database \n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f57fbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to numpy array and get its dimensions\n",
    "data = np.array(data)\n",
    "m, n = data.shape \n",
    "\n",
    "# shuffle data before splitting into dev and training sets\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# take the first 1000 examples as development set and transpose it so each column is an example\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]  # get labels for development set\n",
    "X_dev = data_dev[1:n]  # get features for development set\n",
    "X_dev = X_dev / 255.  # normalize the features\n",
    "\n",
    "# take the remaining examples as training set and transpose it so each column is an example\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]  # get labels for training set\n",
    "X_train = data_train[1:n]  # get features for training set\n",
    "X_train = X_train / 255.  # normalize the features\n",
    "_, m_train = X_train.shape  # get the number of examples in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b72cac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 6, ..., 0, 2, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad8fc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    \"\"\"\n",
    "    Initialize the parameters of a neural network with two hidden layers, where the first hidden layer has 10 neurons and the second hidden layer has 10 neurons. \n",
    "    - The input layer has 784 neurons (corresponding to a 28x28 pixel image), and the output layer has 10 neurons (corresponding to the 10 possible digits). \n",
    "\n",
    "    Returns:\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "    \"\"\"\n",
    "    W1 = np.random.rand(10, 784) - 0.5  # initialize weights for the first hidden layer randomly\n",
    "    b1 = np.random.rand(10, 1) - 0.5  # initialize biases for the first hidden layer randomly\n",
    "    W2 = np.random.rand(10, 10) - 0.5  # initialize weights for the second hidden layer randomly\n",
    "    b2 = np.random.rand(10, 1) - 0.5  # initialize biases for the second hidden layer randomly\n",
    "    W3 = np.random.rand(10, 10)  # initialize weights for the third hidden layer randomly\n",
    "    b3 = np.random.rand(10, 1) # initialize biases for the third hidden layer randomly\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def ReLU(Z):\n",
    "    \"\"\"\n",
    "    Compute the ReLU activation function on a given input Z.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- the input to the ReLU function, a numpy array\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the ReLU function, a numpy array\n",
    "    \"\"\"\n",
    "    return np.maximum(Z, 0)  # apply the ReLU function elementwise to the input Z\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Compute the softmax activation function on a given input Z.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- the input to the softmax function, a numpy array\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the softmax function, a numpy array\n",
    "    \"\"\"\n",
    "    A = np.exp(Z) / sum(np.exp(Z))  # apply the softmax function elementwise to the input Z\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    \"\"\"\n",
    "    Compute the forward propagation of a neural network with two hidden layers.\n",
    "\n",
    "    Arguments:\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "    X -- input data, shape (784, m)\n",
    "\n",
    "    Returns:\n",
    "    Z1 -- output of the linear function of the first hidden layer, shape (10, m)\n",
    "    A1 -- output of the activation function of the first hidden layer, shape (10, m)\n",
    "    Z2 -- output of the linear function of the second hidden layer, shape (10, m)\n",
    "    A2 -- output of the activation function of the second hidden layer, shape (10, m)\n",
    "    \"\"\"\n",
    "    Z1 = W1.dot(X) + b1  # compute the linear function of the first hidden layer\n",
    "    A1 = ReLU(Z1)  # apply the ReLU activation function to the output of the first hidden layer\n",
    "    Z2 = W2.dot(A1) + b2  # compute the linear function of the second hidden layer\n",
    "    A2 = softmax(Z2)  # apply the softmax\n",
    "    Z3 = W3.dot(A2) + b3 # compute the linear function of the third hidden layer\n",
    "    A3 = ReLU(Z3) # apply the ReLU activation function to the output of the new hidden layer\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    \"\"\"\n",
    "    Compute the derivative of the ReLU activation function on a given input Z.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- the input to the ReLU function, a numpy array\n",
    "\n",
    "    Returns:\n",
    "    dA -- the derivative of the ReLU function, a numpy array\n",
    "    \"\"\"\n",
    "    return Z > 0  # compute the derivative of the ReLU function elementwise to the input Z\n",
    "\n",
    "def one_hot(Y):\n",
    "    \"\"\"\n",
    "    Convert a vector of labels into a one-hot encoding.\n",
    "\n",
    "    Arguments:\n",
    "    Y -- a numpy array of labels, shape (m,)\n",
    "\n",
    "    Returns:\n",
    "    one_hot_Y -- the one-hot encoding of Y, shape (n, m)\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))  # initialize a matrix of zeros with dimensions (m, n)\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1  # set the elements of one_hot_Y corresponding to the labels in Y to 1\n",
    "    one_hot_Y = one_hot_Y.T  # transpose the matrix so that each column corresponds to a label\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y):\n",
    "    \"\"\"\n",
    "    Compute the backward propagation of a neural network with two hidden layers.\n",
    "\n",
    "    Arguments:\n",
    "    Z1 -- output of the linear function of the first hidden layer, shape (10, m)\n",
    "    A1 -- output of the activation function of the first hidden layer, shape (10, m)\n",
    "    Z2 -- output of the linear function of the second hidden layer, shape (10, m)\n",
    "    A2 -- output of the activation function of the second hidden layer, shape (10, m)\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    X -- input data, shape (784, m)\n",
    "    Y -- labels, shape (m,)\n",
    "\n",
    "    Returns:\n",
    "    dW1 -- gradient of the cost with respect to W1, shape (10, 784)\n",
    "    db1 -- gradient of the cost with respect to b1, shape (10, 1)\n",
    "    dW2 -- gradient of the cost with respect to W2, shape (10, 10)\n",
    "    db2 -- gradient of the cost with respect to b2, shape (10, 1)\n",
    "    \"\"\"\n",
    "    one_hot_Y = one_hot(Y)  # convert the vector of labels Y into a one-hot encoding\n",
    "    dZ2 = A2 - one_hot_Y  # compute the derivative of the cost function with respect to Z2\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)  # compute the gradient of the cost with respect to W2\n",
    "    db2 = 1 / m * np.sum(dZ2)  # compute the gradient of the cost with respect to b2\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)  # compute the derivative of the cost function with respect to Z1\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)  # compute the gradient of the cost with respect to W1\n",
    "    db1 = 1 / m * np.sum(dZ1)  # compute the gradient of the cost with respect to b1\n",
    "    dZ3 = W3.T.dot(dZ2) * ReLU_deriv(Z3) \n",
    "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    db3 = 1 / m * np.sum(dZ3)\n",
    "\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha):\n",
    "    \"\"\"\n",
    "    Update the parameters of a neural network with two hidden layers using gradient descent.\n",
    "\n",
    "    Arguments:\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "    dW1 -- gradient of the cost with respect to W1, shape (10, 784)\n",
    "    db1 -- gradient of the cost with respect to b1, shape (10, 1)\n",
    "    dW2 -- gradient of the cost with respect to W2, shape (10, 10)\n",
    "    db2 -- gradient of the cost with respect to b2, shape (10, 1)\n",
    "    alpha -- learning rate\n",
    "\n",
    "    Returns:\n",
    "    W1 -- updated weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- updated biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- updated weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- updated biases for the second hidden layer, shape (10, 1)\n",
    "    \"\"\"\n",
    "    W1 = W1 - alpha * dW1  # update the weights for the first hidden layer using gradient descent\n",
    "    b1 = b1 - alpha * db1  # update the biases for the first hidden layer using gradient descent\n",
    "    W2 = W2 - alpha * dW2  # update the weights for the second hidden layer using gradient descent\n",
    "    b2 = b2 - alpha * db2  # update the biases for the second hidden layer using gradient descent\n",
    "    W3 = W3 - alpha * dW3\n",
    "    b3 = b3 - alpha * db3\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3  # return the updated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f02f913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    \"\"\"\n",
    "    Get the predictions of a neural network with two hidden layers.\n",
    "\n",
    "    Arguments:\n",
    "    A2 -- output of the activation function of the second hidden layer, shape (10, m)\n",
    "\n",
    "    Returns:\n",
    "    predictions -- the predicted labels, a numpy array of shape (m,)\n",
    "    \"\"\"\n",
    "    return np.argmax(A2, 0)  # return the index of the maximum value in each column of A2, which corresponds to the predicted label\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a set of predictions.\n",
    "\n",
    "    Arguments:\n",
    "    predictions -- a numpy array of predicted labels, shape (m,)\n",
    "    Y -- a numpy array of true labels, shape (m,)\n",
    "\n",
    "    Returns:\n",
    "    accuracy -- the proportion of correct predictions, a scalar value between 0 and 1\n",
    "    \"\"\"\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size  # count the number of correct predictions and divide by the total number of predictions\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    \"\"\"\n",
    "    Train a neural network with two hidden layers using gradient descent.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, shape (784, m)\n",
    "    Y -- labels, shape (m,)\n",
    "    alpha -- learning rate\n",
    "    iterations -- number of iterations of gradient descent to perform\n",
    "\n",
    "    Returns:\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "    \"\"\"\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()  # initialize the parameters of the neural network\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)  # perform forward propagation to compute the activations of each layer\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y)  # perform backward propagation to compute the gradients of the cost function with respect to each parameter\n",
    "        W1, b1, W2, b2, W3, b3 = update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)  # update the parameters using gradient descent\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)  # get the predictions of the neural network\n",
    "            print(get_accuracy(predictions, Y))  # compute the accuracy of the predictions\n",
    "    return W1, b1, W2, b2, W3, b3 # return the trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f338027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 9 8 ... 9 8 8] [4 3 6 ... 0 2 8]\n",
      "0.0846829268292683\n",
      "Iteration:  10\n",
      "[9 9 8 ... 2 2 8] [4 3 6 ... 0 2 8]\n",
      "0.16909756097560977\n",
      "Iteration:  20\n",
      "[9 9 8 ... 2 2 8] [4 3 6 ... 0 2 8]\n",
      "0.23285365853658538\n",
      "Iteration:  30\n",
      "[9 9 9 ... 2 2 8] [4 3 6 ... 0 2 8]\n",
      "0.3182439024390244\n",
      "Iteration:  40\n",
      "[9 3 9 ... 2 2 8] [4 3 6 ... 0 2 8]\n",
      "0.42534146341463414\n",
      "Iteration:  50\n",
      "[9 3 9 ... 2 9 8] [4 3 6 ... 0 2 8]\n",
      "0.5040975609756098\n",
      "Iteration:  60\n",
      "[9 3 8 ... 2 9 8] [4 3 6 ... 0 2 8]\n",
      "0.5642439024390243\n",
      "Iteration:  70\n",
      "[9 3 8 ... 2 6 8] [4 3 6 ... 0 2 8]\n",
      "0.610390243902439\n",
      "Iteration:  80\n",
      "[9 3 8 ... 0 6 8] [4 3 6 ... 0 2 8]\n",
      "0.651219512195122\n",
      "Iteration:  90\n",
      "[9 3 8 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.6839756097560976\n",
      "Iteration:  100\n",
      "[9 3 8 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7116829268292683\n",
      "Iteration:  110\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7346341463414634\n",
      "Iteration:  120\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7526829268292683\n",
      "Iteration:  130\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7666829268292683\n",
      "Iteration:  140\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.779\n",
      "Iteration:  150\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7888048780487805\n",
      "Iteration:  160\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.7970975609756098\n",
      "Iteration:  170\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8041463414634147\n",
      "Iteration:  180\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8114634146341464\n",
      "Iteration:  190\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8180487804878048\n",
      "Iteration:  200\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8230243902439024\n",
      "Iteration:  210\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8278536585365853\n",
      "Iteration:  220\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8319756097560975\n",
      "Iteration:  230\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8362439024390244\n",
      "Iteration:  240\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8399024390243902\n",
      "Iteration:  250\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8430243902439024\n",
      "Iteration:  260\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8465121951219512\n",
      "Iteration:  270\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8492439024390244\n",
      "Iteration:  280\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8515365853658536\n",
      "Iteration:  290\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8538048780487805\n",
      "Iteration:  300\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8561219512195122\n",
      "Iteration:  310\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8577560975609756\n",
      "Iteration:  320\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8594878048780488\n",
      "Iteration:  330\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8612439024390244\n",
      "Iteration:  340\n",
      "[9 3 6 ... 0 4 8] [4 3 6 ... 0 2 8]\n",
      "0.8629024390243902\n",
      "Iteration:  350\n",
      "[9 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8645853658536585\n",
      "Iteration:  360\n",
      "[9 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8660487804878049\n",
      "Iteration:  370\n",
      "[9 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8673170731707317\n",
      "Iteration:  380\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8687560975609756\n",
      "Iteration:  390\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8703170731707317\n",
      "Iteration:  400\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8713170731707317\n",
      "Iteration:  410\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8723414634146341\n",
      "Iteration:  420\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8736829268292683\n",
      "Iteration:  430\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8748292682926829\n",
      "Iteration:  440\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8761463414634146\n",
      "Iteration:  450\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8769024390243902\n",
      "Iteration:  460\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8779024390243902\n",
      "Iteration:  470\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8786829268292683\n",
      "Iteration:  480\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8795853658536585\n",
      "Iteration:  490\n",
      "[4 3 6 ... 0 9 8] [4 3 6 ... 0 2 8]\n",
      "0.8801463414634146\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, 0.2, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0861db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained neural network with two hidden layers.\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, shape (784, m)\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "\n",
    "    Returns:\n",
    "    predictions -- the predicted labels, a numpy array of shape (m,)\n",
    "    \"\"\"\n",
    "    _, _, _, A2, _, _ = forward_prop(W1, b1, W2, b2, W3, b3, X) # perform forward propagation to compute the activations of each layer\n",
    "    predictions = get_predictions(A2) # get the predicted labels\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2, W3, b3):\n",
    "    \"\"\"\n",
    "    Test the prediction of a trained neural network with two hidden layers on a single image.\n",
    "\n",
    "    Arguments:\n",
    "    index -- the index of the image to test, an integer between 0 and m-1\n",
    "    W1 -- weights for the first hidden layer, shape (10, 784)\n",
    "    b1 -- biases for the first hidden layer, shape (10, 1)\n",
    "    W2 -- weights for the second hidden layer, shape (10, 10)\n",
    "    b2 -- biases for the second hidden layer, shape (10, 1)\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    current_image = X_train[:, index, None]  # extract the current image from the training set\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2, W3, b3)  # make a prediction for the current image using the trained neural network\n",
    "    label = Y_train[index]  # get the true label of the current image\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255  # reshape the image and scale the values to the range [0, 255]\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')  # plot the image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7c1277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [3]\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [6]\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [7]\n",
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(0, W1, b1, W2, b2, W3, b3)\n",
    "test_prediction(1, W1, b1, W2, b2, W3, b3)\n",
    "test_prediction(2, W1, b1, W2, b2, W3, b3)\n",
    "test_prediction(3, W1, b1, W2, b2, W3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1973c3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 8 0 2 2 1 8 9 4 3 6 6 4 1 5 3 0 0 0 9 6 4 9 6 0 9 7 2 7 6 7 1 9 1 3 8\n",
      " 0 7 5 1 4 8 6 1 7 3 9 0 4 1 7 8 4 1 9 9 1 1 5 8 1 6 2 6 2 6 0 7 6 5 0 8 3\n",
      " 3 6 9 1 2 9 9 1 1 8 5 1 7 6 7 5 8 1 2 0 0 3 3 3 0 4 9 2 0 9 0 2 5 1 1 7 5\n",
      " 8 1 9 7 3 0 2 6 5 6 8 0 1 2 1 7 3 8 4 6 8 3 7 3 0 8 2 3 1 4 0 4 1 9 0 4 7\n",
      " 0 1 6 2 7 0 2 4 9 5 1 1 1 2 9 8 3 5 5 1 0 8 5 4 9 7 7 5 2 0 7 5 8 6 1 4 2\n",
      " 2 3 1 2 2 1 3 5 7 9 0 4 6 2 3 7 9 5 6 2 9 0 7 3 5 6 4 6 1 3 2 1 6 4 7 4 1\n",
      " 1 7 6 1 6 7 8 8 5 9 4 4 1 1 3 9 8 9 8 8 7 4 1 0 8 8 3 9 8 2 4 6 9 7 3 1 5\n",
      " 9 9 1 7 6 4 6 4 2 6 3 0 1 1 3 1 4 4 8 9 6 0 2 1 9 7 7 8 4 7 6 2 7 3 5 5 8\n",
      " 7 7 4 9 2 5 0 0 5 7 9 8 6 5 5 3 8 2 1 3 5 6 7 3 0 1 9 9 4 6 0 8 5 7 3 7 9\n",
      " 1 0 8 8 1 6 9 0 7 0 3 8 7 7 8 4 5 0 7 2 4 7 1 6 1 7 9 5 8 2 1 6 6 6 0 7 2\n",
      " 1 9 0 9 7 3 0 9 8 1 9 2 1 8 2 3 0 0 1 0 0 6 9 8 3 3 2 5 2 1 1 1 4 9 0 2 1\n",
      " 7 1 3 3 0 5 1 3 1 3 3 2 3 0 4 5 1 9 6 0 2 7 4 1 2 2 3 2 1 6 0 3 0 7 7 4 3\n",
      " 3 7 5 9 5 7 0 5 4 0 9 2 9 9 3 1 2 2 2 8 2 5 6 7 3 3 5 1 8 8 1 1 6 5 6 5 4\n",
      " 9 0 4 4 4 7 5 5 3 1 8 8 3 9 2 5 6 2 3 3 7 6 3 5 2 1 1 2 4 9 2 1 6 6 2 5 9\n",
      " 7 7 5 2 2 1 1 4 1 0 2 1 1 6 7 8 6 1 1 6 8 2 3 7 1 7 1 1 8 9 4 8 8 1 1 3 5\n",
      " 4 3 2 9 6 1 2 5 8 2 1 5 9 5 9 1 3 4 0 5 2 9 4 8 7 9 9 1 1 1 9 7 6 0 8 6 8\n",
      " 7 1 2 2 7 1 0 4 2 5 0 5 1 7 3 6 0 4 8 6 3 7 8 1 0 4 7 7 4 1 8 2 6 7 3 4 7\n",
      " 6 7 6 2 7 3 7 0 3 3 6 9 5 9 9 4 7 1 9 4 1 2 3 6 7 6 3 2 0 7 6 3 1 9 9 8 7\n",
      " 7 6 1 1 4 1 4 8 0 2 6 7 1 0 1 1 0 7 2 8 5 5 6 0 8 1 8 8 5 4 1 4 6 5 3 9 7\n",
      " 5 1 3 9 4 7 2 1 6 6 7 7 8 0 1 9 3 0 2 4 9 0 1 7 9 6 8 2 1 7 0 6 2 2 3 0 5\n",
      " 2 6 9 1 6 0 6 6 2 1 4 9 3 3 3 9 6 4 2 7 2 3 7 9 5 8 6 8 8 0 2 4 8 7 0 7 2\n",
      " 2 1 1 5 0 9 8 3 1 1 1 1 4 6 7 5 7 6 6 9 5 0 5 3 1 3 2 5 2 9 9 1 0 0 7 7 1\n",
      " 8 2 2 2 0 5 4 6 1 2 6 6 3 5 7 2 9 0 8 5 5 2 1 1 6 3 4 2 6 7 2 0 9 3 9 4 0\n",
      " 0 4 5 2 5 8 0 4 5 1 2 0 1 0 9 9 8 9 7 0 0 6 8 7 7 4 3 4 9 3 4 2 1 0 9 9 1\n",
      " 3 4 8 8 8 8 3 1 1 8 2 6 5 6 0 0 1 6 5 8 1 2 0 6 7 7 1 7 1 2 1 2 1 2 0 8 7\n",
      " 9 0 7 8 6 7 0 0 5 1 3 7 7 9 5 8 7 7 7 5 6 9 0 3 9 8 1 5 9 5 5 3 8 6 7 9 0\n",
      " 7 7 7 4 1 7 2 2 1 8 8 7 8 9 6 9 4 9 1 3 2 9 4 8 4 6 3 1 0 6 5 9 1 7 4 2 0\n",
      " 3] [7 2 9 0 2 2 1 8 9 4 3 6 6 9 1 5 3 5 0 0 9 6 4 9 6 7 9 7 2 7 6 7 1 3 1 3 8\n",
      " 0 7 3 1 4 0 6 1 7 3 9 0 4 1 7 8 4 1 9 9 1 1 5 8 1 6 2 6 2 6 0 7 6 5 0 8 8\n",
      " 3 6 9 1 2 7 3 1 1 8 5 1 7 6 7 5 8 4 2 0 0 3 3 5 0 4 9 2 0 9 0 2 5 1 1 7 5\n",
      " 8 1 9 7 3 0 2 6 6 6 8 0 1 6 1 7 3 8 4 6 8 3 7 3 0 9 2 3 1 4 0 4 1 4 0 4 7\n",
      " 0 1 6 2 7 0 2 4 7 5 1 1 1 2 9 8 3 5 6 1 0 8 5 4 7 7 7 5 3 0 7 5 8 6 1 4 2\n",
      " 2 3 1 2 2 1 3 5 7 9 0 4 6 2 3 7 8 5 6 2 5 0 7 3 5 6 4 6 1 3 2 1 6 4 7 4 2\n",
      " 1 7 6 1 6 7 8 8 5 9 4 4 1 1 3 9 8 9 2 8 7 4 1 0 8 6 3 9 8 6 4 6 9 7 3 1 5\n",
      " 2 9 1 7 6 9 6 4 2 5 2 0 1 1 3 1 4 4 9 7 6 0 2 1 9 7 7 8 4 7 6 2 7 3 5 5 8\n",
      " 7 7 4 9 2 5 0 0 5 7 9 8 6 5 3 3 8 2 1 3 3 6 7 3 0 1 9 9 4 6 0 2 5 7 3 3 9\n",
      " 1 0 8 8 1 6 9 0 7 0 3 8 7 9 8 4 5 0 9 2 4 7 1 6 1 7 9 5 8 8 8 6 6 6 0 7 2\n",
      " 1 9 0 9 9 3 0 9 8 1 9 2 1 8 2 3 0 0 1 0 0 6 7 8 3 3 2 5 2 1 1 1 4 9 0 2 1\n",
      " 7 1 3 3 0 9 1 3 1 3 3 2 5 0 4 8 1 5 6 0 2 7 4 1 9 2 3 2 1 6 0 2 0 7 7 9 3\n",
      " 3 7 5 9 3 7 0 5 4 7 9 2 9 9 3 1 2 0 3 8 2 5 6 7 3 3 5 1 8 8 1 1 6 5 2 6 4\n",
      " 9 0 4 4 4 7 5 0 3 1 5 8 2 9 2 5 6 2 3 3 7 6 3 1 2 1 1 2 4 9 2 1 4 5 2 5 9\n",
      " 7 7 5 2 2 1 1 4 1 0 2 1 1 6 7 8 6 1 1 6 8 2 5 7 1 7 1 1 8 9 4 5 8 1 1 3 5\n",
      " 4 3 2 9 6 1 2 5 9 2 1 5 9 5 9 1 3 4 0 5 2 9 4 8 7 9 9 5 1 1 9 7 6 0 6 8 8\n",
      " 7 1 2 2 7 1 0 4 2 5 0 5 1 3 3 6 0 4 5 6 3 7 8 1 0 4 7 7 4 8 8 2 6 7 3 4 8\n",
      " 6 7 6 2 7 5 7 0 3 3 8 9 5 8 9 4 7 1 4 4 1 2 3 2 7 6 3 2 0 2 2 1 1 9 9 8 9\n",
      " 7 5 8 8 4 1 4 8 0 2 6 7 1 0 1 1 0 7 2 8 5 7 6 0 8 3 8 5 6 4 1 9 6 5 3 9 7\n",
      " 5 1 3 9 4 8 2 1 6 6 7 7 8 0 1 9 3 0 2 4 9 0 1 7 3 6 8 2 1 7 0 6 2 8 3 0 5\n",
      " 2 6 9 7 6 0 6 6 2 1 4 8 3 3 3 9 6 8 2 7 3 3 7 7 3 8 6 8 8 0 8 4 8 7 0 1 2\n",
      " 2 1 1 3 0 9 3 5 1 1 1 1 4 3 7 5 7 6 6 9 5 0 5 3 1 3 4 5 2 9 9 1 0 0 1 7 1\n",
      " 8 2 2 2 0 5 4 6 5 2 6 6 3 5 7 2 9 0 5 0 5 2 1 1 5 5 4 2 6 7 2 0 9 3 9 4 0\n",
      " 0 4 5 2 5 8 0 4 5 1 2 0 1 0 9 9 0 9 7 0 0 6 8 7 7 4 3 4 9 3 4 2 1 0 9 9 1\n",
      " 3 4 8 8 8 8 3 1 1 5 2 6 5 6 0 0 1 5 5 8 1 2 0 6 7 7 1 7 1 2 1 2 1 2 0 8 7\n",
      " 9 0 7 8 6 7 0 0 5 1 3 7 7 9 8 8 7 7 7 5 6 9 0 3 4 8 1 5 9 5 5 3 8 6 7 9 0\n",
      " 7 7 7 4 1 9 0 0 8 5 8 7 2 9 6 4 4 9 1 3 2 9 4 8 4 6 3 1 0 6 1 9 1 7 9 0 0\n",
      " 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.874"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2, W3, b3)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c07371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
